{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>This repository contains essential resources, scripts, and notes for learning and practicing AWS, especially for WorldSkills #53.</p>"},{"location":"#what-youll-find-here","title":"What You'll Find Here:","text":"<ul> <li>Scripts and code snippets for various AWS services.</li> <li>Practical examples and configurations.</li> <li>Key concepts and study notes for WorldSkills preparation.</li> </ul> <p>Feel free to explore and contribute!</p> <p>Contact: juliomacedo.vicente@gmail.com</p> <p>GitHub Repository: AWS Study</p>"},{"location":"AWS/CloudWatch/x-ray/","title":"AWS X-Ray Documentation","text":"<p>AWS X-Ray is a service that enables you to trace requests made to your application in distributed systems, making it easier to identify infrastructure issues and measure the time taken for each request. It is widely used in microservices-based applications.</p>"},{"location":"AWS/CloudWatch/x-ray/#what-is-aws-x-ray","title":"What is AWS X-Ray?","text":"<p>AWS X-Ray helps developers analyze and debug distributed applications, such as those built using a microservices architecture. With X-Ray, you can:</p> <ul> <li>Trace requests as they travel through your application.</li> <li>Identify bottlenecks and performance issues.</li> <li>Gain insights into the behavior of your application.</li> </ul>"},{"location":"AWS/CloudWatch/x-ray/#getting-started-with-aws-x-ray-in-python","title":"Getting Started with AWS X-Ray in Python","text":""},{"location":"AWS/CloudWatch/x-ray/#example-enabling-x-ray-for-popular-libraries","title":"Example: Enabling X-Ray for Popular Libraries","text":"<p>The following example demonstrates how to enable AWS X-Ray to automatically monitor popular libraries in your Python application:</p> <pre><code>from aws_xray_sdk.core import xray_recorder\nfrom aws_xray_sdk.core import patch_all\n\n# Enable X-Ray to monitor popular libraries automatically\npatch_all()\n</code></pre>"},{"location":"AWS/CloudWatch/x-ray/#using-x-ray-middleware","title":"Using X-Ray Middleware","text":"<p>X-Ray middleware integrates with HTTP requests in your application and can be used with frameworks like Flask, Django, etc.</p>"},{"location":"AWS/CloudWatch/x-ray/#example-flask-integration","title":"Example: Flask Integration","text":"<p>The example below shows how to integrate AWS X-Ray with a Flask application:</p> <pre><code>from flask import Flask\nfrom aws_xray_sdk.ext.flask.middleware import XRayMiddleware\nfrom aws_xray_sdk.core import xray_recorder\n\napp = Flask(__name__)\n\n# Configure the service name that will appear in X-Ray\nxray_recorder.configure(service='MyApplication')\n\n# Enable X-Ray middleware in Flask\nXRayMiddleware(app, xray_recorder)\n</code></pre> <p>This setup ensures that all routes in the Flask application are monitored by AWS X-Ray.</p>"},{"location":"AWS/CloudWatch/x-ray/#example-adding-custom-subsegments-in-flask","title":"Example: Adding Custom Subsegments in Flask","text":"<p>The following example demonstrates how to create a custom subsegment within a route in a Flask application:</p> <pre><code>from flask import Flask\nfrom aws_xray_sdk.ext.flask.middleware import XRayMiddleware\nfrom aws_xray_sdk.core import xray_recorder\nimport time\n\napp = Flask(__name__)\nxray_recorder.configure(service='MyApplication')\nXRayMiddleware(app, xray_recorder)\n\n# Default Flask route\n@app.route(\"/process\")\ndef process():\n    # Create a custom subsegment with a personalized name\n    with xray_recorder.in_subsegment('simulating-processing') as subsegment:\n        time.sleep(1.5)  # Simulate processing\n        subsegment.put_metadata('example_data', {'info': 'important value'}, 'custom')\n\n    return \"OK!\"\n</code></pre> <p>This example creates a manual subsegment with AWS X-Ray within a route, allowing you to add custom metadata and simulate processing.</p>"},{"location":"AWS/CloudWatch/x-ray/#best-practices-for-using-aws-x-ray","title":"Best Practices for Using AWS X-Ray","text":"<ol> <li>Use meaningful service names: Ensure that the service names configured in <code>xray_recorder</code> are descriptive and unique.</li> <li>Add custom metadata: Use subsegments to add metadata that can help debug specific parts of your application.</li> <li>Monitor performance: Regularly analyze traces to identify bottlenecks and optimize your application.</li> <li>Integrate with other AWS services: Combine X-Ray with services like CloudWatch for enhanced monitoring and alerting.</li> </ol>"},{"location":"AWS/CloudWatch/x-ray/#additional-resources","title":"Additional Resources","text":"<ul> <li>AWS X-Ray Documentation</li> <li>AWS SDK for Python (Boto3)</li> <li>Flask Documentation</li> </ul>"},{"location":"K8S/api-restfull/","title":"Api restfull","text":"<p>Boa \ud83d\udc4c entendi, voc\u00ea quer uma documenta\u00e7\u00e3o em Markdown, no mesmo estilo da do Istio que me mostrou, mas dessa vez explicando como montar uma self-service REST API usando Lambda + API Gateway + DynamoDB. E dentro da doc vou colocar exemplos de Lambda function em Node.js, Python e at\u00e9 outro (ex: Go).</p> <p>Aqui vai o <code>.md</code>:</p>"},{"location":"K8S/api-restfull/#self-service-restful-api-com-aws-lambda","title":"Self-Service RESTful API com AWS Lambda","text":""},{"location":"K8S/api-restfull/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Amazon API Gateway</li> <li>AWS Lambda</li> <li>Amazon DynamoDB</li> </ul>"},{"location":"K8S/api-restfull/#arquitetura","title":"Arquitetura","text":"<ol> <li>API Gateway exp\u00f5e endpoints REST (<code>/employees</code>).</li> <li>Lambda Functions recebem requisi\u00e7\u00f5es HTTP e processam l\u00f3gica.</li> <li>DynamoDB armazena dados de forma escal\u00e1vel.</li> <li>IAM Roles garantem permiss\u00f5es seguras.</li> </ol>"},{"location":"K8S/api-restfull/#infraestrutura-basica","title":"Infraestrutura B\u00e1sica","text":""},{"location":"K8S/api-restfull/#dynamodb","title":"DynamoDB","text":"<p>Crie a tabela <code>Employees</code>:</p> <ul> <li>Table name: <code>Employees</code></li> <li>Partition key: <code>employeeId (String)</code></li> </ul>"},{"location":"K8S/api-restfull/#variavel-de-ambiente-no-lambda","title":"Vari\u00e1vel de Ambiente no Lambda","text":"<pre><code>DYNAMODB_TABLE=Employees\n</code></pre>"},{"location":"K8S/api-restfull/#exemplo-lambda-python","title":"Exemplo Lambda \u2013 Python","text":"<pre><code>import json\nimport boto3\nimport os\n\ndynamodb = boto3.resource(\"dynamodb\")\ntable = dynamodb.Table(os.environ[\"DYNAMODB_TABLE\"])\n\ndef lambda_handler(event, context):\n    method = event[\"httpMethod\"]\n    path = event[\"path\"]\n\n    if path == \"/employees\" and method == \"GET\":\n        result = table.scan()\n        return response(200, result.get(\"Items\", []))\n    elif path == \"/employees\" and method == \"POST\":\n        body = json.loads(event[\"body\"])\n        table.put_item(Item=body)\n        return response(201, {\"message\": \"Employee created\", \"employee\": body})\n    else:\n        return response(400, {\"error\": \"Unsupported route\"})\n\ndef response(status, body):\n    return {\n        \"statusCode\": status,\n        \"headers\": {\"Content-Type\": \"application/json\"},\n        \"body\": json.dumps(body)\n    }\n</code></pre>"},{"location":"K8S/api-restfull/#exemplo-lambda-nodejs","title":"Exemplo Lambda \u2013 Node.js","text":"<pre><code>const AWS = require(\"aws-sdk\");\nconst dynamodb = new AWS.DynamoDB.DocumentClient();\nconst TABLE_NAME = process.env.DYNAMODB_TABLE;\n\nexports.handler = async (event) =&gt; {\n  const method = event.httpMethod;\n  const path = event.path;\n\n  if (path === \"/employees\" &amp;&amp; method === \"GET\") {\n    const data = await dynamodb.scan({ TableName: TABLE_NAME }).promise();\n    return response(200, data.Items);\n  } else if (path === \"/employees\" &amp;&amp; method === \"POST\") {\n    const body = JSON.parse(event.body);\n    await dynamodb.put({ TableName: TABLE_NAME, Item: body }).promise();\n    return response(201, { message: \"Employee created\", employee: body });\n  } else {\n    return response(400, { error: \"Unsupported route\" });\n  }\n};\n\nfunction response(statusCode, body) {\n  return {\n    statusCode,\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(body),\n  };\n}\n</code></pre>"},{"location":"K8S/api-restfull/#exemplo-lambda-go","title":"Exemplo Lambda \u2013 Go","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"os\"\n\n    \"github.com/aws/aws-lambda-go/events\"\n    \"github.com/aws/aws-lambda-go/lambda\"\n    \"github.com/aws/aws-sdk-go/aws/session\"\n    \"github.com/aws/aws-sdk-go/service/dynamodb\"\n    \"github.com/aws/aws-sdk-go/service/dynamodb/dynamodbattribute\"\n)\n\nvar (\n    db    = dynamodb.New(session.Must(session.NewSession()))\n    table = os.Getenv(\"DYNAMODB_TABLE\")\n)\n\ntype Employee struct {\n    EmployeeID string `json:\"employeeId\"`\n    Name       string `json:\"name\"`\n}\n\nfunc handler(ctx context.Context, req events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n    switch req.HTTPMethod {\n    case \"GET\":\n        result, _ := db.Scan(&amp;dynamodb.ScanInput{TableName: &amp;table})\n        var employees []Employee\n        _ = dynamodbattribute.UnmarshalListOfMaps(result.Items, &amp;employees)\n        body, _ := json.Marshal(employees)\n        return events.APIGatewayProxyResponse{StatusCode: 200, Body: string(body)}, nil\n    case \"POST\":\n        var emp Employee\n        json.Unmarshal([]byte(req.Body), &amp;emp)\n        item, _ := dynamodbattribute.MarshalMap(emp)\n        db.PutItem(&amp;dynamodb.PutItemInput{TableName: &amp;table, Item: item})\n        return events.APIGatewayProxyResponse{StatusCode: 201, Body: fmt.Sprintf(\"Employee %s created\", emp.EmployeeID)}, nil\n    default:\n        return events.APIGatewayProxyResponse{StatusCode: 400, Body: \"Unsupported route\"}, nil\n    }\n}\n\nfunc main() {\n    lambda.Start(handler)\n}\n</code></pre>"},{"location":"K8S/api-restfull/#validacao","title":"Valida\u00e7\u00e3o","text":""},{"location":"K8S/api-restfull/#teste-com-curl","title":"Teste com curl","text":"<pre><code># Criar funcion\u00e1rio\ncurl -X POST https://&lt;api-id&gt;.execute-api.&lt;region&gt;.amazonaws.com/prod/employees \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"employeeId\": \"123\", \"name\": \"Julio\"}'\n\n# Listar funcion\u00e1rios\ncurl https://&lt;api-id&gt;.execute-api.&lt;region&gt;.amazonaws.com/prod/employees\n</code></pre> <p>\ud83d\udc49 Essa doc j\u00e1 cobre: infra m\u00ednima + exemplos em Python, Node.js e Go.</p> <p>Quer que eu adicione tamb\u00e9m uma parte de infra como c\u00f3digo (CloudFormation/SAM ou Terraform) nessa doc, pra j\u00e1 provisionar a API, Lambda e DynamoDB de uma vez?</p>"},{"location":"K8S/Services/ArgoCD/","title":"Argo CD","text":""},{"location":"K8S/Services/ArgoCD/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Argo CD Docs</li> <li>Argo CD CLI</li> </ul>"},{"location":"K8S/Services/ArgoCD/#helm-install","title":"Helm Install","text":"<pre><code>helm repo add argo https://argoproj.github.io/argo-helm\nhelm repo update\n</code></pre> <pre><code># Cria\u00e7\u00e3o do namespace\nkubectl create namespace argocd\n</code></pre> <pre><code># Instala\u00e7\u00e3o do Argo CD via Helm\nhelm upgrade --install argocd argo/argo-cd \\\n  --namespace argocd\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#validacao-da-instalacao","title":"Valida\u00e7\u00e3o da Instala\u00e7\u00e3o","text":"<pre><code># Verificar pods e servi\u00e7os\nkubectl get pods -n argocd\nkubectl get svc -n argocd\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#acesso-ao-argo-cd","title":"Acesso ao Argo CD","text":""},{"location":"K8S/Services/ArgoCD/#opcao-1-port-forward-mais-simples-ambiente-de-lab","title":"Op\u00e7\u00e3o 1: Port-Forward (mais simples, ambiente de lab)","text":"<pre><code>kubectl port-forward svc/argocd-server -n argocd 8080:443\n</code></pre> <p>Acesse no navegador: \ud83d\udc49 https://localhost:8080</p>"},{"location":"K8S/Services/ArgoCD/#opcao-2-loadbalancer-producaoteste-publico","title":"Op\u00e7\u00e3o 2: LoadBalancer (produ\u00e7\u00e3o/teste p\u00fablico)","text":"<pre><code>kubectl patch svc argocd-server -n argocd -p '{\"spec\": {\"type\": \"LoadBalancer\"}}'\nkubectl get svc argocd-server -n argocd\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#senha-inicial","title":"Senha Inicial","text":"<pre><code># Pegar senha inicial do usu\u00e1rio admin\nkubectl get secret argocd-initial-admin-secret -n argocd \\\n  -o jsonpath=\"{.data.password}\" | base64 -d\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#instalacao-do-argocd-cli","title":"Instala\u00e7\u00e3o do ArgoCD CLI","text":""},{"location":"K8S/Services/ArgoCD/#linux","title":"Linux","text":"<pre><code>wget https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64 -O argocd\nchmod +x argocd\nsudo mv argocd /usr/local/bin/\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#mac","title":"Mac","text":"<pre><code>brew install argocd\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#login-via-cli","title":"Login via CLI","text":""},{"location":"K8S/Services/ArgoCD/#se-estiver-usando-port-forward","title":"Se estiver usando port-forward","text":"<pre><code>ARGOCD_PWD=$(kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath=\"{.data.password}\" | base64 -d)\n\nargocd login localhost:8080 \\\n  --username admin \\\n  --password $ARGOCD_PWD \\\n  --insecure\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#se-estiver-usando-loadbalancer","title":"Se estiver usando LoadBalancer","text":"<pre><code>ARGOCD_SERVER=&lt;EXTERNAL-IP-do-argocd-server&gt;\nARGOCD_PWD=$(kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath=\"{.data.password}\" | base64 -d)\n\nargocd login $ARGOCD_SERVER \\\n  --username admin \\\n  --password $ARGOCD_PWD \\\n  --insecure\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#criar-aplicacao-de-exemplo","title":"Criar Aplica\u00e7\u00e3o de Exemplo","text":"<pre><code>argocd app create guestbook \\\n  --repo https://github.com/argoproj/argocd-example-apps.git \\\n  --path guestbook \\\n  --dest-server https://kubernetes.default.svc \\\n  --dest-namespace default\n</code></pre> <pre><code># Sincronizar aplica\u00e7\u00e3o\nargocd app sync guestbook\n</code></pre> <pre><code># Verificar status\nargocd app list\nargocd app get guestbook\n</code></pre>"},{"location":"K8S/Services/ArgoCD/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code># Verificar recursos no cluster\nkubectl get pods,svc -n default\n\n# Verificar apps no ArgoCD\nargocd app list\n</code></pre>"},{"location":"K8S/Services/Hpa/","title":"HPA","text":""},{"location":"K8S/Services/Hpa/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Metrics Server</li> <li>Documenta\u00e7\u00e3o HPA (K8s)</li> <li>Comando <code>kubectl autoscale</code></li> </ul>"},{"location":"K8S/Services/Hpa/#instalacao-do-metrics-server","title":"Instala\u00e7\u00e3o do Metrics Server","text":"<pre><code>kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n</code></pre>"},{"location":"K8S/Services/Hpa/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code>kubectl top nodes\nkubectl top pods\n# Se aparecerem as m\u00e9tricas, est\u00e1 funcionando corretamente\n</code></pre>"},{"location":"K8S/Services/Hpa/#configuracao-recomendada","title":"Configura\u00e7\u00e3o recomendada","text":"<pre><code>kubectl edit deployment metrics-server -n kube-system\n</code></pre> <p>Adicione em <code>args</code>:</p> <pre><code>args:\n- --kubelet-insecure-tls\n- --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\n</code></pre>"},{"location":"K8S/Services/Hpa/#manifesto-do-hpa","title":"Manifesto do HPA","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: monitor-app-hpa\n  namespace: default\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: {{ .Values.deployment.name }}   # Nome do deployment (Helm)\n  minReplicas: 2\n  maxReplicas: 5\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 50        # Escala com uso acima de 50% da CPU\n    - type: Resource\n      resource:\n        name: memory\n        target:\n          type: Utilization\n          averageUtilization: 70        # Escala com uso acima de 70% da Mem\u00f3ria\n</code></pre>"},{"location":"K8S/Services/Hpa/#gerar-hpa-via-comando","title":"Gerar HPA via comando","text":"<pre><code>kubectl autoscale deployment app-name --min=2 --max=10 --cpu-percent=70 --dry-run=client -o yaml &gt; hpa.yaml\n</code></pre>"},{"location":"K8S/Services/Hpa/#monitoramento-do-hpa","title":"Monitoramento do HPA","text":"<pre><code>kubectl get hpa -w    # Exibe o status em tempo real\n</code></pre>"},{"location":"K8S/Services/Hpa/#recurso-obrigatorio-no-deployment","title":"Recurso obrigat\u00f3rio no Deployment","text":"<p>O HPA s\u00f3 funciona se o Deployment definir corretamente os recursos (<code>resources:</code>). Indenta\u00e7\u00e3o errada = HPA n\u00e3o funciona (mostra \"unknown\")</p> <pre><code>spec:\n  containers:\n    - name: app\n      image: {{ .Values.image }}\n      ports:\n        - containerPort: 5000\n      resources:\n        requests:\n          cpu: \"100m\"\n          memory: \"64Mi\"\n        limits:\n          cpu: \"200m\"      # Normalmente nao se limita cpu do container\n          memory: \"128Mi\"\n</code></pre>"},{"location":"K8S/Services/Istio/","title":"Istio","text":""},{"location":"K8S/Services/Istio/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Istio install</li> <li>Istioctl cmd</li> </ul>"},{"location":"K8S/Services/Istio/#helm-install","title":"Helm Install","text":"<pre><code>helm repo add istio https://istio-release.storage.googleapis.com/charts\nhelm repo update\n</code></pre> <pre><code># Istio Base install\nhelm upgrade --install istio-base istio/base -n istio-system --create-namespace\n# Istio istiod install\nhelm upgrade --install istiod istio/istiod -n istio-system\n# Istio ingress install\nhelm upgrade --install istio-ingress istio/gateway -n istio-ingress --create-namespace\n\nkubectl label namespace istio-ingress istio-injection=enabled\n</code></pre>"},{"location":"K8S/Services/Istio/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code>helm ls -n istio-system\nhelm ls -n istio-ingress\n</code></pre>"},{"location":"K8S/Services/Keda/","title":"KEDA","text":""},{"location":"K8S/Services/Keda/#referencia","title":"Refer\u00eancia","text":"<ul> <li>Documenta\u00e7\u00e3o Oficial do KEDA</li> </ul>"},{"location":"K8S/Services/Keda/#instalacao-via-helm","title":"Instala\u00e7\u00e3o via Helm","text":"<pre><code>helm repo add kedacore https://kedacore.github.io/charts\nhelm repo update\nhelm install keda kedacore/keda --namespace keda --create-namespace\n</code></pre>"},{"location":"K8S/Services/Keda/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code>kubectl get pods -n keda         # Verifica se o KEDA foi instalado\nkubectl get scaledobjects        # Lista objetos de escala aplicados\n</code></pre>"},{"location":"K8S/Services/Keda/#exemplo-de-scaledobject-por-uso-de-cpu","title":"Exemplo de ScaledObject por uso de CPU","text":"<pre><code>apiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: cpu-scaledobject\nspec:\n  scaleTargetRef:\n    name: {{ .Values.deployment.name }}   # Nome do deployment alvo (valor Helm)\n  minReplicaCount: 1\n  maxReplicaCount: 5                      # Sempre defina os limites\n  triggers:\n    - type: cpu\n      metadata:\n        type: Utilization\n        value: \"50\"                       # Escala se uso da CPU &gt; 50%\n</code></pre>"},{"location":"K8S/Services/Keda/#trigger-para-aws-sqs","title":"Trigger para AWS SQS","text":"<pre><code>triggers:\n  - type: aws-sqs-queue\n    metadata:\n      queueURLFromEnv: QUEUE_URL     # OU use diretamente 'queueURL'\n      queueLength: \"5\"               # Tamanho da fila para escalar (default: 5)\n      awsRegion: \"us-east-1\"         # Regi\u00e3o da fila\n      awsEndpoint: \"\"                # Opcional: endpoint customizado\n</code></pre>"},{"location":"K8S/Services/NginxIngress/","title":"Nginx Ingress","text":""},{"location":"K8S/Services/NginxIngress/#referencia","title":"Refer\u00eancia","text":"<ul> <li>Documenta\u00e7\u00e3o Oficial do NGINX Ingress</li> </ul>"},{"location":"K8S/Services/NginxIngress/#instalacao-via-helm-do-nginx-ingress-controller","title":"Instala\u00e7\u00e3o via Helm do NGINX Ingress Controller","text":"<pre><code>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\nhelm repo update\n</code></pre> <pre><code>helm upgrade --install ingress-nginx ingress-nginx \\\n  --repo https://kubernetes.github.io/ingress-nginx \\\n  --namespace ingress-nginx --create-namespace \\\n  --set controller.replicaCount=2 \\\n  --set controller.service.type=LoadBalancer\n</code></pre>"},{"location":"K8S/Services/NginxIngress/#exemplo-de-canary-deployment-separando-25-para-a-versao-canary","title":"Exemplo de Canary Deployment separando 25% para a vers\u00e3o canary","text":""},{"location":"K8S/Services/NginxIngress/#ingress-stable-75","title":"Ingress Stable (75%)","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-api-ingress\n  namespace: default # namespace default mudar para o seu\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            # O tr\u00e1fego principal que ser\u00e1 75% vai para o stable\n            name: stable-service\n            port:\n              number: 80\n</code></pre>"},{"location":"K8S/Services/NginxIngress/#ingress-canary-25","title":"Ingress Canary (25%)","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-api-ingress-canary\n  namespace: default\n  annotations:\n    nginx.ingress.kubernetes.io/canary: \"true\"          # ativa o modo canary\n    nginx.ingress.kubernetes.io/canary-weight: \"25\"     # separa 25% para o canary\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            # o tr\u00e1fego do canary ser\u00e1 25%\n            name: canary-service\n            port:\n              number: 80\n</code></pre>"},{"location":"K8S/Services/eksauth/","title":"EKS \u2013 ClusterRole e ClusterRoleBinding para Console","text":""},{"location":"K8S/Services/eksauth/#referencias","title":"Refer\u00eancias","text":"<ul> <li>AWS EKS \u2013 Cluster Authentication</li> <li>RBAC Kubernetes</li> <li>eksctl Docs</li> </ul>"},{"location":"K8S/Services/eksauth/#criando-com-kubectl","title":"Criando com kubectl","text":""},{"location":"K8S/Services/eksauth/#clusterrole","title":"ClusterRole","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: eks-console-dashboard-full-access\nrules:\n- apiGroups: [\"\"]\n  resources: [\"nodes\", \"pods\", \"services\", \"endpoints\", \"namespaces\", \"events\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <pre><code>kubectl apply -f clusterrole-eks-console.yaml\n</code></pre>"},{"location":"K8S/Services/eksauth/#clusterrolebinding","title":"ClusterRoleBinding","text":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: eks-console-dashboard-full-access-binding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: eks-console-dashboard-full-access\nsubjects:\n- kind: User\n  name: eks-console-dashboard-reporter\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <pre><code>kubectl apply -f clusterrolebinding-eks-console.yaml\n</code></pre>"},{"location":"K8S/Services/eksauth/#criando-com-eksctl","title":"Criando com eksctl","text":""},{"location":"K8S/Services/eksauth/#arquivo-de-configuracao-eks-console-accessyaml","title":"Arquivo de Configura\u00e7\u00e3o (<code>eks-console-access.yaml</code>)","text":"<pre><code>apiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: jam-cluster\n  region: us-east-1   # ajuste para a sua regi\u00e3o\n\nkubernetes:\n  clusterRoles:\n    - name: eks-console-dashboard-full-access\n      rules:\n        - apiGroups: [\"\"]\n          resources: [\"nodes\", \"pods\", \"services\", \"endpoints\", \"namespaces\", \"events\"]\n          verbs: [\"get\", \"list\", \"watch\"]\n\n  clusterRoleBindings:\n    - metadata:\n        name: eks-console-dashboard-full-access-binding\n      roleRef:\n        apiGroup: rbac.authorization.k8s.io\n        kind: ClusterRole\n        name: eks-console-dashboard-full-access\n      subjects:\n        - kind: User\n          name: eks-console-dashboard-reporter\n          apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"K8S/Services/eksauth/#aplicar","title":"Aplicar","text":"<pre><code>eksctl utils apply -f eks-console-access.yaml --approve\n</code></pre>"},{"location":"K8S/Services/eksauth/#validacao","title":"Valida\u00e7\u00e3o","text":""},{"location":"K8S/Services/eksauth/#pelo-console-aws","title":"Pelo Console AWS","text":"<ol> <li> <p>V\u00e1 em EKS &gt; Clusters &gt; jam-cluster &gt; Nodes    \u2192 Os nodes agora devem aparecer.</p> </li> <li> <p>V\u00e1 em Events e procure pelo evento com Reason = RegisteredNode.</p> </li> </ol> <p>Poss\u00edveis valores no campo From:</p> <ul> <li><code>kubelet</code> (mais comum, o agente no node)</li> <li><code>node-controller</code> (controlador do kube-controller-manager)</li> <li><code>cloud-controller-manager</code> (casos raros em ambientes cloud)</li> </ul>"},{"location":"K8S/Services/eksauth/#pelo-kubectl","title":"Pelo kubectl","text":"<pre><code>kubectl get events -A --field-selector reason=RegisteredNode\n</code></pre> <p>apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig</p> <p>metadata:   name: funny-alternative-mountain   region: us-east-1   version: \"1.33\"</p> <p>managedNodeGroups: - name: nodegroup   desiredCapacity: 3   instanceType: t2.small   ssh:     enableSsm: true</p> <p>vpc:   id: vpc-0994bcd9ba10a742b   subnets:     public:       us-east-1a: { id: \"subnet-022878b0be20d9b41\" }       us-east-1b: { id: \"subnet-0b50f6175bf1b3bf9\" }   securityGroup: \"sg-0e8cbfecf16e470a9\"</p>"},{"location":"K8S/Services/karpenter/","title":"Karpenter","text":""},{"location":"K8S/Services/karpenter/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Karpenter Docs</li> <li>AWS EKS + Karpenter</li> </ul>"},{"location":"K8S/Services/karpenter/#helm-install","title":"Helm Install","text":"<pre><code>helm repo add karpenter https://charts.karpenter.sh\nhelm repo update\n</code></pre> <pre><code># Namespace e ServiceAccount para o controller\nkubectl create namespace karpenter\nkubectl annotate serviceaccount -n karpenter default \\\n  eks.amazonaws.com/role-arn=arn:aws:iam::&lt;ACCOUNT_ID&gt;:role/karpenter-controller-role \\\n  --overwrite\n</code></pre> <pre><code># Instala\u00e7\u00e3o do Karpenter\nhelm upgrade --install karpenter karpenter/karpenter \\\n  --namespace karpenter \\\n  --set settings.clusterName=&lt;CLUSTER_NAME&gt; \\\n  --set settings.clusterEndpoint=&lt;CLUSTER_ENDPOINT&gt; \\\n  --set settings.aws.defaultInstanceProfile=karpenter-node-instance-profile \\\n  --set serviceAccount.annotations.\"eks\\.amazonaws\\.com/role-arn\"=arn:aws:iam::&lt;ACCOUNT_ID&gt;:role/karpenter-controller-role\n</code></pre>"},{"location":"K8S/Services/karpenter/#nodeclass-e-nodepool","title":"NodeClass e NodePool","text":"<pre><code># ec2nodeclass.yaml\napiVersion: karpenter.k8s.aws/v1beta1\nkind: EC2NodeClass\nmetadata:\n  name: default-ec2\nspec:\n  amiFamily: AL2023\n  role: karpenter-node-role\n  subnetSelectorTerms:\n    - tags:\n        kubernetes.io/cluster/&lt;CLUSTER_NAME&gt;: shared\n  securityGroupSelectorTerms:\n    - tags:\n        kubernetes.io/cluster/&lt;CLUSTER_NAME&gt;: owned\n</code></pre> <pre><code># nodepool.yaml\napiVersion: karpenter.sh/v1beta1\nkind: NodePool\nmetadata:\n  name: default\nspec:\n  template:\n    spec:\n      nodeClassRef:\n        name: default-ec2\n      requirements:\n        - key: \"node.kubernetes.io/instance-type\"\n          operator: In\n          values: [\"t3.medium\",\"t3.large\"]\n  limits:\n    cpu: \"1000\"\n    memory: 1000Gi\n</code></pre> <pre><code>kubectl apply -f ec2nodeclass.yaml\nkubectl apply -f nodepool.yaml\n</code></pre>"},{"location":"K8S/Services/karpenter/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code># Verificar pods do Karpenter\nkubectl get pods -n karpenter\n\n# Teste de escala (um deployment que pede 5 r\u00e9plicas)\nkubectl create deployment inflate --image=public.ecr.aws/eks-distro/kubernetes/pause:3.2 --replicas=5\nkubectl get nodes -o wide\n</code></pre>"},{"location":"K8S/Services/promeGrafa/","title":"Prometheus &amp;&amp; Grafana","text":""},{"location":"K8S/Services/promeGrafa/#referencias","title":"Refer\u00eancias","text":"<ul> <li>AWS Docs \u2013 Deploy Prometheus no EKS</li> <li>Artigo Medium \u2013 Prometheus + Grafana no K8s</li> </ul>"},{"location":"K8S/Services/promeGrafa/#instalacao-via-helm","title":"Instala\u00e7\u00e3o via Helm","text":""},{"location":"K8S/Services/promeGrafa/#adicionar-repositorios","title":"Adicionar reposit\u00f3rios","text":"<pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#instalar-prometheus","title":"Instalar Prometheus","text":"<pre><code>helm install prometheus prometheus-community/prometheus \\\n  --namespace monitoring --create-namespace\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#instalar-grafana","title":"Instalar Grafana","text":"<pre><code>helm install grafana grafana/grafana \\\n  --namespace monitoring --create-namespace\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code>kubectl get all -n monitoring\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#acesso-via-port-forward","title":"Acesso via port-forward","text":""},{"location":"K8S/Services/promeGrafa/#grafana","title":"Grafana","text":"<pre><code>kubectl port-forward svc/grafana 3000:80 -n monitoring\n</code></pre> <p>Acesse: http://localhost:3000 Usu\u00e1rio: <code>admin</code> Senha:</p> <pre><code>kubectl get secret grafana -n monitoring -o jsonpath=\"{.data.admin-password}\" | base64 --decode\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#prometheus","title":"Prometheus","text":"<pre><code>kubectl port-forward svc/prometheus-server 9090:80 -n monitoring\n</code></pre> <p>Acesse: http://localhost:9090</p>"},{"location":"K8S/Services/promeGrafa/#instalacao-do-prometheus-e-grafana-com-node-selector","title":"Instala\u00e7\u00e3o do Prometheus e Grafana com Node Selector","text":""},{"location":"K8S/Services/promeGrafa/#criar-arquivos-de-configuracao","title":"Criar arquivos de configura\u00e7\u00e3o","text":""},{"location":"K8S/Services/promeGrafa/#prometheus-valuesyaml","title":"prometheus-values.yaml","text":"<pre><code>nodeSelector:\n  nodegroup: monitoring\n\nprometheus:\n  nodeSelector:\n    nodegroup: monitoring\n  service:\n    type: ClusterIP\n\nalertmanager:\n  nodeSelector:\n    nodegroup: monitoring\n\ngrafana:\n  nodeSelector:\n    nodegroup: monitoring\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#grafana-valuesyaml","title":"grafana-values.yaml","text":"<pre><code>nodeSelector:\n  nodegroup: monitoring\n\ngrafana:\n  additionalDataSources:\n    - name: Prometheus\n      type: prometheus\n      url: http://kube-prometheus-kube-prome-prometheus.monitoring.svc.cluster.local:9090\n      access: proxy\n      isDefault: true\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#comandos-de-instalacao","title":"Comandos de instala\u00e7\u00e3o","text":"<pre><code># Adicionar reposit\u00f3rios Helm\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n\n# Instalar Prometheus Stack\nhelm install kube-prometheus prometheus-community/kube-prometheus-stack \\\n  -f prometheus-values.yaml \\\n  --namespace monitoring \\\n  --create-namespace\n\n# Instalar Grafana  \nhelm install grafana grafana/grafana \\\n  -f grafana-values.yaml \\\n  --namespace monitoring \\\n  --create-namespace\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#verificar-instalacao","title":"Verificar instala\u00e7\u00e3o","text":"<pre><code>kubectl get pods -n monitoring -o wide\n</code></pre>"},{"location":"K8S/Services/promeGrafa/#acessar-os-servicos","title":"Acessar os servi\u00e7os","text":"<p><pre><code># Prometheus\nkubectl port-forward -n monitoring pod/prometheus-kube-prometheus-kube-prome-prometheus-0 9090\n\n# Grafana\nkubectl port-forward svc/grafana 3000:80 -n monitoring\n</code></pre> Credenciais Grafana: - Usu\u00e1rio: admin - Senha: <code>kubectl get secret grafana -n monitoring -o jsonpath=\"{.data.admin-password}\" | base64 --decode</code> </p>"},{"location":"K8S/manifest/testCpu/","title":"Stress de CPU no Kubernetes","text":""},{"location":"K8S/manifest/testCpu/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Artigo Medium</li> <li>Guia stress-ng</li> <li>Imagem Docker polinux/stress-ng</li> </ul>"},{"location":"K8S/manifest/testCpu/#namespace-para-o-teste","title":"Namespace para o teste","text":"<pre><code>kubectl create namespace monitor\n</code></pre>"},{"location":"K8S/manifest/testCpu/#manifesto-de-teste-cpu-stress","title":"Manifesto de teste (CPU Stress)","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: {{ .Values.test.name }}        # Nome vindo do values.yaml (Helm)\n  namespace: monitor\nspec:\n  containers:\n    - name: stress\n      image: polinux/stress-ng\n      command: [ \"stress-ng\" ]\n      args: [ \"--cpu\", \"2\", \"--cpu-method\", \"fft\", \"--timeout\", \"300s\" ]  \n      # Usa 2 CPUs com carga alta por 300 segundos (FFT)\n  restartPolicy: Never\n</code></pre>"},{"location":"K8S/manifest/testCpu/#aplicar-o-teste","title":"Aplicar o teste","text":"<pre><code>kubectl apply -f test-memory-cpu.yaml\n</code></pre>"},{"location":"K8S/manifest/testCpu/#validar-execucao","title":"Validar execu\u00e7\u00e3o","text":"<pre><code>kubectl get pods -n monitor\n</code></pre>"},{"location":"Packages/AmazonLinux/","title":"AmazonLinux Packages","text":"<p>Quick reference guide for installing and configuring essential development tools for Amazon Linux AWS environments.</p>"},{"location":"Packages/AmazonLinux/#packages","title":"Packages","text":""},{"location":"Packages/AmazonLinux/#aws-cli","title":"AWS CLI","text":"<pre><code># AWS CLI v2 (latest)\ncurl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" &amp;&amp; \\\nunzip awscliv2.zip &amp;&amp; \\\nsudo ./aws/install &amp;&amp; \\\nrm -rf aws awscliv2.zip\n</code></pre> <pre><code># Verify installation\naws --version\n</code></pre>"},{"location":"Packages/AmazonLinux/#curl","title":"curl","text":"<pre><code># Install curl\nsudo yum install -y curl\n</code></pre> <pre><code># Verify installation\ncurl --version\n</code></pre>"},{"location":"Packages/AmazonLinux/#docker","title":"Docker","text":"<pre><code># Install and configure Docker\nsudo amazon-linux-extras install docker -y &amp;&amp; \\\nsudo systemctl enable --now docker &amp;&amp; \\\nsudo usermod -aG docker $USER &amp;&amp; \\\nnewgrp docker\n</code></pre> <pre><code># Verify installation\ndocker --version\n</code></pre>"},{"location":"Packages/AmazonLinux/#jq","title":"jq","text":"<pre><code># Install jq JSON processor\nsudo yum install -y jq\n</code></pre> <pre><code># Verify installation\njq --version\n</code></pre>"},{"location":"Packages/AmazonLinux/#kubectl","title":"kubectl","text":"<pre><code># Install kubectl\ncurl -Lo kubectl \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" &amp;&amp; \\\nchmod +x kubectl &amp;&amp; \\\nsudo mv kubectl /usr/local/bin/ &amp;&amp; \\\necho 'source &lt;(kubectl completion bash)' &gt;&gt;~/.bashrc\n</code></pre> <pre><code># Verify installation\nkubectl version --client\n</code></pre> <pre><code># Configure kubectl for EKS\naws eks update-kubeconfig --region &lt;region&gt; --name &lt;cluster-name&gt;\n</code></pre>"},{"location":"Packages/AmazonLinux/#template-for-adding-new-tools","title":"Template for Adding New Tools","text":"<pre><code>## Tool Name\n\n```bash\n# Install tool\ninstallation commands\n</code></pre> <pre><code># Verify installation\nverification command\n</code></pre>"},{"location":"Packages/WindowsServer/","title":"WindowsServer Packages","text":"<p>Quick reference guide for installing and configuring essential development tools for Windows Server AWS environments.</p>"},{"location":"Packages/WindowsServer/#packages","title":"Packages","text":""},{"location":"Packages/WindowsServer/#aws-cli-v2","title":"AWS CLI v2","text":"<pre><code>&lt;powershell&gt;\n# Baixa o instalador oficial do AWS CLI v2 para uma pasta tempor\u00e1ria\nInvoke-WebRequest -Uri \"https://awscli.amazonaws.com/AWSCLIV2.msi\" -OutFile \"$env:TEMP\\AWSCLIV2.msi\"\n\n# Instala o AWS CLI de forma silenciosa e aguarda a conclus\u00e3o\nStart-Process msiexec.exe -ArgumentList \"/i `\"$env:TEMP\\AWSCLIV2.msi`\" /qn\" -Wait\n&lt;/powershell&gt;\n</code></pre>"},{"location":"Packages/WindowsServer/#verify-installation","title":"Verify installation","text":"<pre><code>aws --version\n</code></pre>"},{"location":"Packages/WindowsServer/#iis","title":"IIS","text":"<pre><code>&lt;powershell&gt;\nInstall-WindowsFeature -name Web-Server -IncludeManagementTools\n&lt;/powershell&gt;\n</code></pre>"},{"location":"Packages/buildspec/","title":"AWS CodeBuild \u2013 Buildspec (Python)","text":""},{"location":"Packages/buildspec/#referencia","title":"Refer\u00eancia","text":"<ul> <li>Documenta\u00e7\u00e3o Oficial do Buildspec</li> </ul>"},{"location":"Packages/buildspec/#estrutura-do-buildspecyaml","title":"Estrutura do buildspec.yaml","text":"<pre><code>version: 0.2\n\nphases:\n  install:        # Instala\u00e7\u00e3o de depend\u00eancias e setup do ambiente\n    runtime-versions:\n      python: 3.9\n    commands:\n      - echo \"Instalando depend\u00eancias Python...\"\n      - pip install --upgrade pip\n      - pip install -r requirements.txt\n\n  pre_build:      # Passos antes do build, como testes unit\u00e1rios\n    commands:\n      - echo \"Executando testes...\"\n      - pytest --maxfail=1 --disable-warnings -q\n\n  build:          # Fase principal de build\n    commands:\n      - echo \"Rodando aplica\u00e7\u00e3o / empacotando projeto\"\n      - python setup.py sdist bdist_wheel || echo \"Sem setup.py, apenas rodando script\"\n\n  post_build:     # Etapas finais (artefatos, valida\u00e7\u00f5es)\n    commands:\n      - echo \"Build conclu\u00eddo em `date`\"\n      - ls -lh\n\nartifacts:        # Arquivos que ser\u00e3o exportados como resultado\n  files:\n    - '**/*'\n  discard-paths: no\n</code></pre>"},{"location":"Packages/buildspec/#exemplo-1-aplicacao-python-simples","title":"Exemplo 1 \u2013 Aplica\u00e7\u00e3o Python Simples","text":"<pre><code>version: 0.2\n\nphases:\n  install:\n    runtime-versions:\n      python: 3.9\n    commands:\n      - echo \"Instalando depend\u00eancias\"\n      - pip install -r requirements.txt\n\n  build:\n    commands:\n      - echo \"Rodando aplica\u00e7\u00e3o Python\"\n      - python main.py\n\nartifacts:\n  files:\n    - '**/*'\n</code></pre>"},{"location":"Packages/buildspec/#exemplo-2-python-testes-unitarios","title":"Exemplo 2 \u2013 Python + Testes Unit\u00e1rios","text":"<pre><code>version: 0.2\n\nphases:\n  install:\n    runtime-versions:\n      python: 3.10\n    commands:\n      - echo \"Instalando pacotes necess\u00e1rios\"\n      - pip install -r requirements.txt\n      - pip install pytest\n\n  pre_build:\n    commands:\n      - echo \"Executando testes unit\u00e1rios\"\n      - pytest tests/ --junitxml=reports/tests.xml\n\n  build:\n    commands:\n      - echo \"Empacotando projeto\"\n      - python setup.py sdist\n\nartifacts:\n  files:\n    - dist/**/*\n    - reports/tests.xml\n</code></pre>"},{"location":"Packages/buildspec/#exemplo-3-python-docker-ecr-deploy","title":"Exemplo 3 \u2013 Python + Docker (ECR Deploy)","text":"<pre><code>version: 0.2\n\nphases:\n  pre_build:\n    commands:\n      - echo \"Logando no Amazon ECR...\"\n      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n      - REPOSITORY_URI=&lt;AWS_ACCOUNT_ID&gt;.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/meu-repo-python\n      - IMAGE_TAG=$(date +%Y%m%d%H%M%S)\n  build:\n    commands:\n      - echo \"Build da imagem Docker\"\n      - docker build -t $REPOSITORY_URI:$IMAGE_TAG .\n  post_build:\n    commands:\n      - echo \"Fazendo push da imagem\"\n      - docker push $REPOSITORY_URI:$IMAGE_TAG\n      - echo \"Gerando imagedefinitions.json para deploy\"\n      - printf '[{\"name\":\"python-app\",\"imageUri\":\"%s\"}]' $REPOSITORY_URI:$IMAGE_TAG &gt; imagedefinitions.json\n\nartifacts:\n  files:\n    - imagedefinitions.json\n</code></pre> <p>Esse \u00faltimo \u00e9 \u00fatil quando o Python roda dentro de container e o deploy acontece no ECS ou EKS.</p>"},{"location":"Packages/Coder/vscoder/","title":"Coder","text":""},{"location":"Packages/Coder/vscoder/#referencias","title":"Refer\u00eancias","text":"<ul> <li> Coder Server </li> <li> Script coder </li> </ul>"},{"location":"Packages/Coder/vscoder/#instalacao","title":"Instala\u00e7\u00e3o","text":"<pre><code>curl -fsSL https://code-server.dev/install.sh | sh\nsudo systemctl enable --now code-server@$USER\n</code></pre> <p>Dentro do arquivo config.yaml configure para o seu servidor <pre><code>vim /home/ubuntu/.config/code-server/config.yaml\n\nbind-addr: 0.0.0.0:8080 # escutando todas as interfaces\nauth: password\npassword: '$PASSWORD' # variavel de uma senha\ncert: false\n</code></pre></p> <p>Valida\u00e7\u00e3o <pre><code>sudo systemctl restart code-server@ubuntu\nsudo systemctl status code-server@ubuntu\n</code></pre></p>"}]}